# tools/voice_tool.py
from langchain.tools import BaseTool
from pydantic import BaseModel, Field
from typing import Type, Optional
import speech_recognition as sr
from gtts import gTTS
import pygame
import os
import tempfile

class VoiceInput(BaseModel):
    """è¯­éŸ³å·¥å…·çš„è¾“å…¥schema"""
    message: str = Field(description="è¦é€šè¿‡è¯­éŸ³è¯´å‡ºçš„æ¶ˆæ¯å†…å®¹")
    listen: bool = Field(
        default=False, 
        description="æ˜¯å¦éœ€è¦ç­‰å¾…ç”¨æˆ·è¯­éŸ³è¾“å…¥ã€‚Trueè¡¨ç¤ºéœ€è¦å¬ç”¨æˆ·è¯´è¯ï¼ŒFalseè¡¨ç¤ºåªæ’­æ”¾æ¶ˆæ¯"
    )

class VoiceInteractionTool(BaseTool):
    name = "voice_interaction"
    description = """
    ç”¨äºä¸ç”¨æˆ·è¿›è¡Œè¯­éŸ³äº¤äº’çš„å·¥å…·ã€‚å¯ä»¥ï¼š
    1. å°†æ–‡å­—è½¬æ¢ä¸ºè¯­éŸ³æ’­æ”¾ç»™ç”¨æˆ·
    2. æ¥æ”¶ç”¨æˆ·çš„è¯­éŸ³è¾“å…¥å¹¶è½¬æ¢ä¸ºæ–‡å­—
    
    è¾“å…¥å‚æ•°ï¼š
    - message: è¦è¯´ç»™ç”¨æˆ·å¬çš„å†…å®¹
    - listen: æ˜¯å¦éœ€è¦ç­‰å¾…ç”¨æˆ·çš„è¯­éŸ³å›å¤ (True/False)
    
    ä½¿ç”¨åœºæ™¯ï¼šå½“éœ€è¦è¯­éŸ³æ’­æŠ¥ä¿¡æ¯æˆ–è·å–ç”¨æˆ·è¯­éŸ³è¾“å…¥æ—¶ä½¿ç”¨ã€‚
    """
    args_schema: Type[BaseModel] = VoiceInput
    
    def __init__(self):
        super().__init__()
        self.recognizer = sr.Recognizer()
        pygame.mixer.init()
    
    def _text_to_speech(self, text: str, lang: str = 'zh-CN'):
        """æ–‡å­—è½¬è¯­éŸ³å¹¶æ’­æ”¾"""
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:
                temp_file = fp.name
            
            # ç”Ÿæˆè¯­éŸ³
            tts = gTTS(text=text, lang=lang)
            tts.save(temp_file)
            
            # æ’­æ”¾è¯­éŸ³
            pygame.mixer.music.load(temp_file)
            pygame.mixer.music.play()
            
            # ç­‰å¾…æ’­æ”¾å®Œæˆ
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_file)
            
            return True
        except Exception as e:
            return f"è¯­éŸ³æ’­æ”¾å¤±è´¥: {str(e)}"
    
    def _speech_to_text(self, timeout: int = 5) -> str:
        """è¯­éŸ³è½¬æ–‡å­—"""
        try:
            with sr.Microphone() as source:
                print("ğŸ¤ æ­£åœ¨å¬å–ç”¨æˆ·è¾“å…¥...")
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                audio = self.recognizer.listen(source, timeout=timeout)
                
                # ä½¿ç”¨Googleè¯­éŸ³è¯†åˆ«ï¼ˆæ”¯æŒä¸­æ–‡ï¼‰
                text = self.recognizer.recognize_google(audio, language='zh-CN')
                print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}")
                return text
        except sr.WaitTimeoutError:
            return "æœªæ£€æµ‹åˆ°è¯­éŸ³è¾“å…¥"
        except sr.UnknownValueError:
            return "æ— æ³•è¯†åˆ«è¯­éŸ³å†…å®¹"
        except Exception as e:
            return f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}"
    
    def _run(self, message: str, listen: bool = False) -> str:
        """æ‰§è¡Œè¯­éŸ³äº¤äº’"""
        result = []
        
        # 1. æ’­æ”¾æ¶ˆæ¯ç»™ç”¨æˆ·
        if message:
            tts_result = self._text_to_speech(message)
            if tts_result is True:
                result.append(f"âœ… å·²è¯­éŸ³æ’­æ”¾: {message}")
            else:
                result.append(f"âŒ {tts_result}")
        
        # 2. å¦‚æœéœ€è¦ï¼Œç›‘å¬ç”¨æˆ·è¾“å…¥
        if listen:
            user_input = self._speech_to_text()
            result.append(f"ç”¨æˆ·è¯­éŸ³è¾“å…¥: {user_input}")
            return "\n".join(result) + f"\nç”¨æˆ·è¯´: {user_input}"
        
        return "\n".join(result)
    
    async def _arun(self, message: str, listen: bool = False) -> str:
        """å¼‚æ­¥æ‰§è¡Œ"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥")